{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "                                               title  target\n0  Clinical features of culture-proven Mycoplasma...       0\n1  Nitric oxide: a pro-inflammatory mediator in l...       0\n2    Surfactant protein-D and pulmonary host defense       0\n3               Role of endothelin-1 in lung disease       0\n4  Gene expression in epithelial cells in respons...       0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Clinical features of culture-proven Mycoplasma...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Nitric oxide: a pro-inflammatory mediator in l...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Surfactant protein-D and pulmonary host defense</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Role of endothelin-1 in lung disease</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Gene expression in epithelial cells in respons...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#read csv\n",
    "df = pd.read_csv('CORD19_abstract.csv')\n",
    "df.head()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-29T22:31:53.320789Z",
     "start_time": "2023-05-29T22:31:52.048681Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "                                               title  target\n0  Clinical features of culture-proven Mycoplasma...       0\n1  Nitric oxide: a pro-inflammatory mediator in l...       0\n2    Surfactant protein-D and pulmonary host defense       0\n3               Role of endothelin-1 in lung disease       0\n4  Gene expression in epithelial cells in respons...       0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Clinical features of culture-proven Mycoplasma...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Nitric oxide: a pro-inflammatory mediator in l...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Surfactant protein-D and pulmonary host defense</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Role of endothelin-1 in lung disease</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Gene expression in epithelial cells in respons...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop rows with missing values\n",
    "df = df.dropna()\n",
    "df.head()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-29T22:31:53.449856Z",
     "start_time": "2023-05-29T22:31:53.433223Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                   title  target\n11779  Scope, quality, and inclusivity of clinical gu...       1\n25959  Moral panic about “covidiots” in Canadian news...       1\n31336  Commentary to the paper: Association of smokin...       1\n46437  The pathogenesis of thromboembolic disease in ...       1\n49266      Music and the internet in the age of covid-19       1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>11779</th>\n      <td>Scope, quality, and inclusivity of clinical gu...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>25959</th>\n      <td>Moral panic about “covidiots” in Canadian news...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>31336</th>\n      <td>Commentary to the paper: Association of smokin...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>46437</th>\n      <td>The pathogenesis of thromboembolic disease in ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>49266</th>\n      <td>Music and the internet in the age of covid-19</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df['title'].str.contains('covid')]\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-29T22:32:06.033350Z",
     "start_time": "2023-05-29T22:32:05.640678Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi , Kevin Mastascusa\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1056660 entries, 0 to 1056659\n",
      "Data columns (total 19 columns):\n",
      " #   Column            Non-Null Count    Dtype  \n",
      "---  ------            --------------    -----  \n",
      " 0   cord_uid          1056660 non-null  object \n",
      " 1   sha               373766 non-null   object \n",
      " 2   source_x          1056660 non-null  object \n",
      " 3   title             1056157 non-null  object \n",
      " 4   doi               656780 non-null   object \n",
      " 5   pmcid             389571 non-null   object \n",
      " 6   pubmed_id         498932 non-null   object \n",
      " 7   license           1056660 non-null  object \n",
      " 8   abstract          821118 non-null   object \n",
      " 9   publish_time      1054846 non-null  object \n",
      " 10  authors           1032791 non-null  object \n",
      " 11  journal           969338 non-null   object \n",
      " 12  mag_id            0 non-null        float64\n",
      " 13  who_covidence_id  482935 non-null   object \n",
      " 14  arxiv_id          14249 non-null    object \n",
      " 15  pdf_json_files    373766 non-null   object \n",
      " 16  pmc_json_files    315742 non-null   object \n",
      " 17  url               686934 non-null   object \n",
      " 18  s2_id             976468 non-null   float64\n",
      "dtypes: float64(2), object(17)\n",
      "memory usage: 153.2+ MB\n",
      "None\n",
      "   cord_uid                                       sha source_x  \\\n",
      "0  ug7v899j  d1aafb70c066a2068b02786f8929fd9c900897fb      PMC   \n",
      "1  02tnwd4m  6b0567729c2143a66d737eb0a2f63f2dce2e5a7d      PMC   \n",
      "2  ejv2xln0  06ced00a5fc04215949aa72528f2eeaae1d58927      PMC   \n",
      "3  2b73a28n  348055649b6b8cf2b9a376498df9bf41f7123605      PMC   \n",
      "4  9785vg6d  5f48792a5fa08bed9f56016f4981ae2ca6031b32      PMC   \n",
      "5  zjufx4fo  b2897e1277f56641193a6db73825f707eed3e4c9      PMC   \n",
      "6  5yhe786e  3bb07ea10432f7738413dff9816809cc90f03f99      PMC   \n",
      "7  8zchiykl  5806726a24dc91de3954001effbdffd7a82d54e2      PMC   \n",
      "8  8qnrcgnk  faaf1022ccfe93b032c5608097a53543ba24aedb      PMC   \n",
      "9  jg13scgo  5b44feca5d6ffaaeb66501fa84cc6dd44d06660a      PMC   \n",
      "\n",
      "                                               title  \\\n",
      "0  Clinical features of culture-proven Mycoplasma...   \n",
      "1  Nitric oxide: a pro-inflammatory mediator in l...   \n",
      "2    Surfactant protein-D and pulmonary host defense   \n",
      "3               Role of endothelin-1 in lung disease   \n",
      "4  Gene expression in epithelial cells in respons...   \n",
      "5  Sequence requirements for RNA strand transfer ...   \n",
      "6  Debate: Transfusing to normal haemoglobin leve...   \n",
      "7  The 21st International Symposium on Intensive ...   \n",
      "8  Heme oxygenase-1 and carbon monoxide in pulmon...   \n",
      "9  Technical Description of RODS: A Real-time Pub...   \n",
      "\n",
      "                        doi      pmcid pubmed_id    license  \\\n",
      "0     10.1186/1471-2334-1-6   PMC35282  11472636      no-cc   \n",
      "1              10.1186/rr14   PMC59543  11667967      no-cc   \n",
      "2              10.1186/rr19   PMC59549  11667972      no-cc   \n",
      "3              10.1186/rr44   PMC59574  11686871      no-cc   \n",
      "4              10.1186/rr61   PMC59580  11686888      no-cc   \n",
      "5  10.1093/emboj/20.24.7220  PMC125340  11742998   green-oa   \n",
      "6             10.1186/cc987  PMC137267  11299062      no-cc   \n",
      "7            10.1186/cc1013  PMC137274  11353930      no-cc   \n",
      "8     10.1186/1465-9921-4-7  PMC193681  12964953      no-cc   \n",
      "9       10.1197/jamia.m1345  PMC212776  12807803  bronze-oa   \n",
      "\n",
      "                                            abstract publish_time  \\\n",
      "0  OBJECTIVE: This retrospective chart review des...   2001-07-04   \n",
      "1  Inflammatory diseases of the respiratory tract...   2000-08-15   \n",
      "2  Surfactant protein-D (SP-D) participates in th...   2000-08-25   \n",
      "3  Endothelin-1 (ET-1) is a 21 amino acid peptide...   2001-02-22   \n",
      "4  Respiratory syncytial virus (RSV) and pneumoni...   2001-05-11   \n",
      "5  Nidovirus subgenomic mRNAs contain a leader se...   2001-12-17   \n",
      "6  Recent evidence suggests that critically ill p...   2001-03-08   \n",
      "7  The 21st International Symposium on Intensive ...   2001-05-02   \n",
      "8  Heme oxygenase-1 (HO-1), an inducible stress p...   2003-08-07   \n",
      "9  This report describes the design and implement...   2003-09-01   \n",
      "\n",
      "                                             authors  \\\n",
      "0                Madani, Tariq A; Al-Ghamdi, Aisha A   \n",
      "1  Vliet, Albert van der; Eiserich, Jason P; Cros...   \n",
      "2                                    Crouch, Erika C   \n",
      "3  Fagan, Karen A; McMurtry, Ivan F; Rodman, David M   \n",
      "4  Domachowske, Joseph B; Bonville, Cynthia A; Ro...   \n",
      "5  Pasternak, Alexander O.; van den Born, Erwin; ...   \n",
      "6    Alvarez, Gonzalo; Hébert, Paul C; Szick, Sharyn   \n",
      "7                      Ball, Jonathan; Venn, Richard   \n",
      "8  Slebos, Dirk-Jan; Ryter, Stefan W; Choi, Augus...   \n",
      "9  Tsui, Fu-Chiang; Espino, Jeremy U.; Dato, Virg...   \n",
      "\n",
      "                                             journal  mag_id who_covidence_id  \\\n",
      "0                                     BMC Infect Dis     NaN              NaN   \n",
      "1                                         Respir Res     NaN              NaN   \n",
      "2                                         Respir Res     NaN              NaN   \n",
      "3                                         Respir Res     NaN              NaN   \n",
      "4                                         Respir Res     NaN              NaN   \n",
      "5                                   The EMBO Journal     NaN              NaN   \n",
      "6                                          Crit Care     NaN              NaN   \n",
      "7                                          Crit Care     NaN              NaN   \n",
      "8                                         Respir Res     NaN              NaN   \n",
      "9  Journal of the American Medical Informatics As...     NaN              NaN   \n",
      "\n",
      "  arxiv_id                                     pdf_json_files  \\\n",
      "0      NaN  document_parses/pdf_json/d1aafb70c066a2068b027...   \n",
      "1      NaN  document_parses/pdf_json/6b0567729c2143a66d737...   \n",
      "2      NaN  document_parses/pdf_json/06ced00a5fc04215949aa...   \n",
      "3      NaN  document_parses/pdf_json/348055649b6b8cf2b9a37...   \n",
      "4      NaN  document_parses/pdf_json/5f48792a5fa08bed9f560...   \n",
      "5      NaN  document_parses/pdf_json/b2897e1277f56641193a6...   \n",
      "6      NaN  document_parses/pdf_json/3bb07ea10432f7738413d...   \n",
      "7      NaN  document_parses/pdf_json/5806726a24dc91de39540...   \n",
      "8      NaN  document_parses/pdf_json/faaf1022ccfe93b032c56...   \n",
      "9      NaN  document_parses/pdf_json/5b44feca5d6ffaaeb6650...   \n",
      "\n",
      "                                pmc_json_files  \\\n",
      "0   document_parses/pmc_json/PMC35282.xml.json   \n",
      "1   document_parses/pmc_json/PMC59543.xml.json   \n",
      "2   document_parses/pmc_json/PMC59549.xml.json   \n",
      "3   document_parses/pmc_json/PMC59574.xml.json   \n",
      "4   document_parses/pmc_json/PMC59580.xml.json   \n",
      "5  document_parses/pmc_json/PMC125340.xml.json   \n",
      "6  document_parses/pmc_json/PMC137267.xml.json   \n",
      "7  document_parses/pmc_json/PMC137274.xml.json   \n",
      "8  document_parses/pmc_json/PMC193681.xml.json   \n",
      "9  document_parses/pmc_json/PMC212776.xml.json   \n",
      "\n",
      "                                                 url  s2_id  \n",
      "0  https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3...    NaN  \n",
      "1  https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5...    NaN  \n",
      "2  https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5...    NaN  \n",
      "3  https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5...    NaN  \n",
      "4  https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5...    NaN  \n",
      "5  http://europepmc.org/articles/pmc125340?pdf=re...    NaN  \n",
      "6  https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1...    NaN  \n",
      "7  https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1...    NaN  \n",
      "8  https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1...    NaN  \n",
      "9  https://academic.oup.com/jamia/article-pdf/10/...    NaN  \n",
      "        cord_uid                                       sha source_x    title  \\\n",
      "count    1056660                                    373766  1056660  1056157   \n",
      "unique    970836                                    373719       49   850366   \n",
      "top     kgpo6psq  31bc0fb718edaab9e33f678909710f62c40abebc      WHO    Reply   \n",
      "freq         192                                         3   450459      251   \n",
      "mean         NaN                                       NaN      NaN      NaN   \n",
      "std          NaN                                       NaN      NaN      NaN   \n",
      "min          NaN                                       NaN      NaN      NaN   \n",
      "25%          NaN                                       NaN      NaN      NaN   \n",
      "50%          NaN                                       NaN      NaN      NaN   \n",
      "75%          NaN                                       NaN      NaN      NaN   \n",
      "max          NaN                                       NaN      NaN      NaN   \n",
      "\n",
      "                                    doi     pmcid   pubmed_id  license  \\\n",
      "count                            656780    389571    498932.0  1056660   \n",
      "unique                           655525    389571    498587.0       18   \n",
      "top     10.1016/j.scitotenv.2020.139397  PMC35282  35087663.0      unk   \n",
      "freq                                  9         1         5.0   601506   \n",
      "mean                                NaN       NaN         NaN      NaN   \n",
      "std                                 NaN       NaN         NaN      NaN   \n",
      "min                                 NaN       NaN         NaN      NaN   \n",
      "25%                                 NaN       NaN         NaN      NaN   \n",
      "50%                                 NaN       NaN         NaN      NaN   \n",
      "75%                                 NaN       NaN         NaN      NaN   \n",
      "max                                 NaN       NaN         NaN      NaN   \n",
      "\n",
      "                   abstract publish_time     authors   journal  mag_id  \\\n",
      "count                821118      1054846     1032791    969338     0.0   \n",
      "unique               730713         8056      796659     54993     NaN   \n",
      "top     [Figure: see text].         2021  Anonymous,  PLoS One     NaN   \n",
      "freq                    206       233709        3904      9953     NaN   \n",
      "mean                    NaN          NaN         NaN       NaN     NaN   \n",
      "std                     NaN          NaN         NaN       NaN     NaN   \n",
      "min                     NaN          NaN         NaN       NaN     NaN   \n",
      "25%                     NaN          NaN         NaN       NaN     NaN   \n",
      "50%                     NaN          NaN         NaN       NaN     NaN   \n",
      "75%                     NaN          NaN         NaN       NaN     NaN   \n",
      "max                     NaN          NaN         NaN       NaN     NaN   \n",
      "\n",
      "         who_covidence_id     arxiv_id  \\\n",
      "count              482935  14249.00000   \n",
      "unique             482935  14249.00000   \n",
      "top     #covidwho-1638294   2110.00181   \n",
      "freq                    1      1.00000   \n",
      "mean                  NaN          NaN   \n",
      "std                   NaN          NaN   \n",
      "min                   NaN          NaN   \n",
      "25%                   NaN          NaN   \n",
      "50%                   NaN          NaN   \n",
      "75%                   NaN          NaN   \n",
      "max                   NaN          NaN   \n",
      "\n",
      "                                           pdf_json_files  \\\n",
      "count                                              373766   \n",
      "unique                                             373719   \n",
      "top     document_parses/pdf_json/31bc0fb718edaab9e33f6...   \n",
      "freq                                                    3   \n",
      "mean                                                  NaN   \n",
      "std                                                   NaN   \n",
      "min                                                   NaN   \n",
      "25%                                                   NaN   \n",
      "50%                                                   NaN   \n",
      "75%                                                   NaN   \n",
      "max                                                   NaN   \n",
      "\n",
      "                                    pmc_json_files  \\\n",
      "count                                       315742   \n",
      "unique                                      315742   \n",
      "top     document_parses/pmc_json/PMC35282.xml.json   \n",
      "freq                                             1   \n",
      "mean                                           NaN   \n",
      "std                                            NaN   \n",
      "min                                            NaN   \n",
      "25%                                            NaN   \n",
      "50%                                            NaN   \n",
      "75%                                            NaN   \n",
      "max                                            NaN   \n",
      "\n",
      "                                                      url         s2_id  \n",
      "count                                              686934  9.764680e+05  \n",
      "unique                                             686934           NaN  \n",
      "top     https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3...           NaN  \n",
      "freq                                                    1           NaN  \n",
      "mean                                                  NaN  2.175871e+08  \n",
      "std                                                   NaN  5.312281e+07  \n",
      "min                                                   NaN  9.600000e+01  \n",
      "25%                                                   NaN  2.211411e+08  \n",
      "50%                                                   NaN  2.320829e+08  \n",
      "75%                                                   NaN  2.373948e+08  \n",
      "max                                                   NaN  2.491936e+08  \n",
      "cord_uid                  0\n",
      "sha                  682894\n",
      "source_x                  0\n",
      "title                   503\n",
      "doi                  399880\n",
      "pmcid                667089\n",
      "pubmed_id            557728\n",
      "license                   0\n",
      "abstract             235542\n",
      "publish_time           1814\n",
      "authors               23869\n",
      "journal               87322\n",
      "mag_id              1056660\n",
      "who_covidence_id     573725\n",
      "arxiv_id            1042411\n",
      "pdf_json_files       682894\n",
      "pmc_json_files       740918\n",
      "url                  369726\n",
      "s2_id                 80192\n",
      "dtype: int64\n",
      "cord_uid            970836\n",
      "sha                 373719\n",
      "source_x                49\n",
      "title               850366\n",
      "doi                 655525\n",
      "pmcid               389571\n",
      "pubmed_id           498587\n",
      "license                 18\n",
      "abstract            730713\n",
      "publish_time          8056\n",
      "authors             796659\n",
      "journal              54993\n",
      "mag_id                   0\n",
      "who_covidence_id    482935\n",
      "arxiv_id             14249\n",
      "pdf_json_files      373719\n",
      "pmc_json_files      315742\n",
      "url                 686934\n",
      "s2_id               678262\n",
      "dtype: int64\n",
      " ------------------------------------ \n",
      " ------------------------------------ \n",
      "Drop the columns that are not required:\n",
      "Check the structure of the data:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1056660 entries, 0 to 1056659\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count    Dtype \n",
      "---  ------  --------------    ----- \n",
      " 0   title   1056157 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 8.1+ MB\n",
      "None\n",
      "Print the first 10 rows of the data:\n",
      "                                               title\n",
      "0  Clinical features of culture-proven Mycoplasma...\n",
      "1  Nitric oxide: a pro-inflammatory mediator in l...\n",
      "2    Surfactant protein-D and pulmonary host defense\n",
      "3               Role of endothelin-1 in lung disease\n",
      "4  Gene expression in epithelial cells in respons...\n",
      "5  Sequence requirements for RNA strand transfer ...\n",
      "6  Debate: Transfusing to normal haemoglobin leve...\n",
      "7  The 21st International Symposium on Intensive ...\n",
      "8  Heme oxygenase-1 and carbon monoxide in pulmon...\n",
      "9  Technical Description of RODS: A Real-time Pub...\n",
      "Print a summary of the data:\n",
      "          title\n",
      "count   1056157\n",
      "unique   850366\n",
      "top       Reply\n",
      "freq        251\n",
      "Number of missing values in each column:\n",
      "title    503\n",
      "dtype: int64\n",
      "Number of unique values in each column:\n",
      "title    850366\n",
      "dtype: int64\n",
      "Drop the rows with missing values:\n",
      "Number of missing values in each column:\n",
      "title    0\n",
      "dtype: int64\n",
      "Number of unique values in each column:\n",
      "title    850366\n",
      "dtype: int64\n",
      "MARKER 1\n",
      " ------------------------------------ \n",
      " ------------------------------------ \n",
      "Add target column for classification:\n",
      "Print the first 10 rows of the data:\n",
      "                                               title  target\n",
      "0  Clinical features of culture-proven Mycoplasma...       0\n",
      "1  Nitric oxide: a pro-inflammatory mediator in l...       0\n",
      "2    Surfactant protein-D and pulmonary host defense       0\n",
      "3               Role of endothelin-1 in lung disease       0\n",
      "4  Gene expression in epithelial cells in respons...       0\n",
      "5  Sequence requirements for RNA strand transfer ...       0\n",
      "6  Debate: Transfusing to normal haemoglobin leve...       0\n",
      "7  The 21st International Symposium on Intensive ...       0\n",
      "8  Heme oxygenase-1 and carbon monoxide in pulmon...       0\n",
      "9  Technical Description of RODS: A Real-time Pub...       0\n",
      "Number of missing values in each column:\n",
      "title     0\n",
      "target    0\n",
      "dtype: int64\n",
      "Number of unique values in each column:\n",
      "title     850366\n",
      "target         2\n",
      "dtype: int64\n",
      "Class distribution:\n",
      "0    612031\n",
      "1    444126\n",
      "Name: target, dtype: int64\n",
      "Class distribution plot:\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ------------------------------------ \n",
      " ------------------------------------ \n",
      "MARKER 2\n",
      " ------------------------------------ \n",
      " ------------------------------------ \n",
      "Data Preprocessing:\n",
      "NUMPY ARRAY CONVERSION:\n",
      "Convert the dataframe to numpy array:\n",
      "Print the numpy array:\n",
      "[['Clinical features of culture-proven Mycoplasma pneumoniae infections at King Abdulaziz University Hospital, Jeddah, Saudi Arabia'\n",
      "  0]\n",
      " ['Nitric oxide: a pro-inflammatory mediator in lung disease?' 0]\n",
      " ['Surfactant protein-D and pulmonary host defense' 0]\n",
      " ...\n",
      " ['A Patient With Bilateral Conjunctivitis Positive for SARS-CoV-2 RNA in a Conjunctival Sample'\n",
      "  0]\n",
      " ['Incidental lowering of otitis-media complaints in otitis-prone children during COVID-19 pandemic: not all evil comes to hurt'\n",
      "  1]\n",
      " ['Hospital variation in admissions to neonatal intensive care units by diagnosis severity and category'\n",
      "  0]]\n",
      "Print the shape of the numpy array:\n",
      "(1056157, 2)\n",
      "Print the type of the numpy array:\n",
      "<class 'numpy.ndarray'>\n",
      "Print the first row of the numpy array:\n",
      "['Clinical features of culture-proven Mycoplasma pneumoniae infections at King Abdulaziz University Hospital, Jeddah, Saudi Arabia'\n",
      " 0]\n",
      "Print the second row of the numpy array:\n",
      "['Nitric oxide: a pro-inflammatory mediator in lung disease?' 0]\n",
      "Print the third row of the numpy array:\n",
      "['Surfactant protein-D and pulmonary host defense' 0]\n",
      "Print the fourth row of the numpy array:\n",
      "['Role of endothelin-1 in lung disease' 0]\n",
      "Print the fifth row of the numpy array:\n",
      "['Gene expression in epithelial cells in response to pneumovirus infection'\n",
      " 0]\n",
      "Print the first column of the numpy array:\n",
      "['Clinical features of culture-proven Mycoplasma pneumoniae infections at King Abdulaziz University Hospital, Jeddah, Saudi Arabia'\n",
      " 'Nitric oxide: a pro-inflammatory mediator in lung disease?'\n",
      " 'Surfactant protein-D and pulmonary host defense' ...\n",
      " 'A Patient With Bilateral Conjunctivitis Positive for SARS-CoV-2 RNA in a Conjunctival Sample'\n",
      " 'Incidental lowering of otitis-media complaints in otitis-prone children during COVID-19 pandemic: not all evil comes to hurt'\n",
      " 'Hospital variation in admissions to neonatal intensive care units by diagnosis severity and category']\n",
      "Print the second column of the numpy array:\n",
      "[0 0 0 ... 0 1 0]\n",
      "Print the first row and first column of the numpy array:\n",
      "Clinical features of culture-proven Mycoplasma pneumoniae infections at King Abdulaziz University Hospital, Jeddah, Saudi Arabia\n",
      "Print the first row and second column of the numpy array:\n",
      "0\n",
      "Export as csv file:\n",
      "['title,target\\n', '\"Clinical features of culture-proven Mycoplasma pneumoniae infections at King Abdulaziz University Hospital, Jeddah, Saudi Arabia\",0\\n', 'Nitric oxide: a pro-inflammatory mediator in lung disease?,0\\n', 'Surfactant protein-D and pulmonary host defense,0\\n', 'Role of endothelin-1 in lung disease,0\\n']\n",
      " ------------------------------------ \n",
      " ------------------------------------ \n",
      "Download the stopwords:\n",
      "text cleaning:\n",
      "Convert to lower case:\n",
      "Remove punctuation:\n",
      "Remove numbers:\n",
      "Remove whitespaces:\n",
      "Print the first 5 rows of the data:\n",
      "                                               title  target\n",
      "0  clinical features of cultureproven mycoplasma ...       0\n",
      "1  nitric oxide a proinflammatory mediator in lun...       0\n",
      "2     surfactant proteind and pulmonary host defense       0\n",
      "3                 role of endothelin in lung disease       0\n",
      "4  gene expression in epithelial cells in respons...       0\n",
      "Number of missing values in each column:\n",
      "title     0\n",
      "target    0\n",
      "dtype: int64\n",
      "Number of unique values in each column:\n",
      "title     767546\n",
      "target         2\n",
      "dtype: int64\n",
      "Class distribution:\n",
      "0    612031\n",
      "1    444126\n",
      "Name: target, dtype: int64\n",
      "Class distribution plot:\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ------------------------------------ \n",
      " ------------------------------------ \n",
      "KNN:\n",
      "Import the libraries:\n",
      "Create the features and labels:\n",
      "Split the data into training and testing sets:\n",
      "Initialize the TfidfVectorizer:\n",
      "Fit and transform the training data:\n",
      "Transform the test set:\n",
      "Initialize the KNN classifier:\n",
      "Fit the model:\n",
      "Predict on the test set:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [2]\u001B[0m, in \u001B[0;36m<cell line: 558>\u001B[0;34m()\u001B[0m\n\u001B[1;32m    556\u001B[0m \u001B[38;5;66;03m# Predict on the test set\u001B[39;00m\n\u001B[1;32m    557\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mPredict on the test set:\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m--> 558\u001B[0m y_pred \u001B[38;5;241m=\u001B[39m \u001B[43mknn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtfidf_test\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    559\u001B[0m \u001B[38;5;66;03m# Print the accuracy score\u001B[39;00m\n\u001B[1;32m    560\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mPrint the accuracy score:\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neighbors/_classification.py:226\u001B[0m, in \u001B[0;36mKNeighborsClassifier.predict\u001B[0;34m(self, X)\u001B[0m\n\u001B[1;32m    210\u001B[0m \u001B[38;5;124;03m\"\"\"Predict the class labels for the provided data.\u001B[39;00m\n\u001B[1;32m    211\u001B[0m \n\u001B[1;32m    212\u001B[0m \u001B[38;5;124;03mParameters\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    221\u001B[0m \u001B[38;5;124;03m    Class labels for each data sample.\u001B[39;00m\n\u001B[1;32m    222\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    223\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mweights \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124muniform\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m    224\u001B[0m     \u001B[38;5;66;03m# In that case, we do not need the distances to perform\u001B[39;00m\n\u001B[1;32m    225\u001B[0m     \u001B[38;5;66;03m# the weighting so we do not compute them.\u001B[39;00m\n\u001B[0;32m--> 226\u001B[0m     neigh_ind \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkneighbors\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreturn_distance\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m    227\u001B[0m     neigh_dist \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    228\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neighbors/_base.py:796\u001B[0m, in \u001B[0;36mKNeighborsMixin.kneighbors\u001B[0;34m(self, X, n_neighbors, return_distance)\u001B[0m\n\u001B[1;32m    793\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    794\u001B[0m         kwds \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39meffective_metric_params_\n\u001B[0;32m--> 796\u001B[0m     chunked_results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[1;32m    797\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpairwise_distances_chunked\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    798\u001B[0m \u001B[43m            \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    799\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fit_X\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    800\u001B[0m \u001B[43m            \u001B[49m\u001B[43mreduce_func\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreduce_func\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    801\u001B[0m \u001B[43m            \u001B[49m\u001B[43mmetric\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43meffective_metric_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    802\u001B[0m \u001B[43m            \u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_jobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    803\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    804\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    805\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    807\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fit_method \u001B[38;5;129;01min\u001B[39;00m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mball_tree\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mkd_tree\u001B[39m\u001B[38;5;124m\"\u001B[39m]:\n\u001B[1;32m    808\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m issparse(X):\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/metrics/pairwise.py:1850\u001B[0m, in \u001B[0;36mpairwise_distances_chunked\u001B[0;34m(X, Y, reduce_func, metric, n_jobs, working_memory, **kwds)\u001B[0m\n\u001B[1;32m   1848\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1849\u001B[0m     X_chunk \u001B[38;5;241m=\u001B[39m X[sl]\n\u001B[0;32m-> 1850\u001B[0m D_chunk \u001B[38;5;241m=\u001B[39m \u001B[43mpairwise_distances\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_chunk\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mY\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmetric\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmetric\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_jobs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1851\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (X \u001B[38;5;129;01mis\u001B[39;00m Y \u001B[38;5;129;01mor\u001B[39;00m Y \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;129;01mand\u001B[39;00m PAIRWISE_DISTANCE_FUNCTIONS\u001B[38;5;241m.\u001B[39mget(\n\u001B[1;32m   1852\u001B[0m     metric, \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1853\u001B[0m ) \u001B[38;5;129;01mis\u001B[39;00m euclidean_distances:\n\u001B[1;32m   1854\u001B[0m     \u001B[38;5;66;03m# zeroing diagonal, taking care of aliases of \"euclidean\",\u001B[39;00m\n\u001B[1;32m   1855\u001B[0m     \u001B[38;5;66;03m# i.e. \"l2\"\u001B[39;00m\n\u001B[1;32m   1856\u001B[0m     D_chunk\u001B[38;5;241m.\u001B[39mflat[sl\u001B[38;5;241m.\u001B[39mstart :: _num_samples(X) \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/metrics/pairwise.py:2022\u001B[0m, in \u001B[0;36mpairwise_distances\u001B[0;34m(X, Y, metric, n_jobs, force_all_finite, **kwds)\u001B[0m\n\u001B[1;32m   2019\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m distance\u001B[38;5;241m.\u001B[39msquareform(distance\u001B[38;5;241m.\u001B[39mpdist(X, metric\u001B[38;5;241m=\u001B[39mmetric, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds))\n\u001B[1;32m   2020\u001B[0m     func \u001B[38;5;241m=\u001B[39m partial(distance\u001B[38;5;241m.\u001B[39mcdist, metric\u001B[38;5;241m=\u001B[39mmetric, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m-> 2022\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_parallel_pairwise\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mY\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/metrics/pairwise.py:1563\u001B[0m, in \u001B[0;36m_parallel_pairwise\u001B[0;34m(X, Y, func, n_jobs, **kwds)\u001B[0m\n\u001B[1;32m   1560\u001B[0m X, Y, dtype \u001B[38;5;241m=\u001B[39m _return_float_dtype(X, Y)\n\u001B[1;32m   1562\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m effective_n_jobs(n_jobs) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m-> 1563\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mY\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1565\u001B[0m \u001B[38;5;66;03m# enforce a threading backend to prevent data communication overhead\u001B[39;00m\n\u001B[1;32m   1566\u001B[0m fd \u001B[38;5;241m=\u001B[39m delayed(_dist_wrapper)\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/metrics/pairwise.py:328\u001B[0m, in \u001B[0;36meuclidean_distances\u001B[0;34m(X, Y, Y_norm_squared, squared, X_norm_squared)\u001B[0m\n\u001B[1;32m    322\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m Y_norm_squared\u001B[38;5;241m.\u001B[39mshape \u001B[38;5;241m!=\u001B[39m (\u001B[38;5;241m1\u001B[39m, Y\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]):\n\u001B[1;32m    323\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    324\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIncompatible dimensions for Y of shape \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mY\u001B[38;5;241m.\u001B[39mshape\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m and \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    325\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mY_norm_squared of shape \u001B[39m\u001B[38;5;132;01m{\u001B[39;00moriginal_shape\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    326\u001B[0m         )\n\u001B[0;32m--> 328\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_euclidean_distances\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mY\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_norm_squared\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mY_norm_squared\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msquared\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/metrics/pairwise.py:372\u001B[0m, in \u001B[0;36m_euclidean_distances\u001B[0;34m(X, Y, X_norm_squared, Y_norm_squared, squared)\u001B[0m\n\u001B[1;32m    370\u001B[0m     distances \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m XX\n\u001B[1;32m    371\u001B[0m     distances \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m YY\n\u001B[0;32m--> 372\u001B[0m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmaximum\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdistances\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdistances\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    374\u001B[0m \u001B[38;5;66;03m# Ensure that distances between vectors and themselves are set to 0.0.\u001B[39;00m\n\u001B[1;32m    375\u001B[0m \u001B[38;5;66;03m# This may not be the case due to floating point rounding errors.\u001B[39;00m\n\u001B[1;32m    376\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m X \u001B[38;5;129;01mis\u001B[39;00m Y:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# PROGRAM HEADER NAME: KEVIN MASTASCUSA DESCRIPTION: This program is a data science project that uses the CORD-19\n",
    "# dataset to perform sentiment analysis on the abstracts of the papers. The program will use the abstracts to\n",
    "# determine if the paper is about COVID-19 or not. DATE: VERSION: 1.0 USAGE: python main.py\n",
    "# ================================================================================================================\n",
    "\n",
    "# Import the required libraries\n",
    "import math  # For mathematical operations\n",
    "import random  # For random number generation\n",
    "import os  # For file operations\n",
    "import pandas as pd  # For data manipulation and analysis\n",
    "import numpy as np  # For mathematical calculations\n",
    "import matplotlib.pyplot as plt  # For data visualization\n",
    "import seaborn as sns  # For data visualization\n",
    "import warnings  # To ignore any warnings\n",
    "import nltk  # Natural Language Toolkit\n",
    "import re  # For regular expressions\n",
    "import string  # For string operations\n",
    "from nltk.corpus import stopwords  # To identify and remove the stopwords\n",
    "from nltk.stem.porter import PorterStemmer  # To perform stemming\n",
    "from nltk.tokenize import word_tokenize  # To create tokens from text\n",
    "from nltk.stem import WordNetLemmatizer  # To perform lemmatization\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer  # For feature extraction\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer  # For feature extraction\n",
    "from sklearn.model_selection import train_test_split  # To split the data into train and test set\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, \\\n",
    "    classification_report  # To measure how well the model is performing\n",
    "from sklearn.neighbors import KNeighborsClassifier  # KNN classifier\n",
    "from sklearn.naive_bayes import MultinomialNB  # Naive Bayes classifier\n",
    "from sklearn.tree import DecisionTreeClassifier  # Decision Tree classifier\n",
    "\n",
    "# nltk.download('punkt')  # punkt is a pre-trained model that helps you tokenize words and sentences\n",
    "# nltk.download('wordnet')  # wordnet is a lexical database for the English language\n",
    "# nltk.download('stopwords')  # stopwords are the words in any language which does not add much meaning to a sentence\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "import nltk\n",
    "\n",
    "\n",
    "# nltk.download()\n",
    "\n",
    "\n",
    "def print_hi(name):\n",
    "    \"\"\"\n",
    "    This function prints the name of the user\n",
    "\n",
    "\n",
    "\n",
    "    :param name:\n",
    "    \"\"\"\n",
    "    print(f'Hi , {name}')\n",
    "\n",
    "\n",
    "def main():\n",
    "    print(f'Welcome to the CORD-19 Sentiment Analysis Project')\n",
    "    print(f'Please select an option from the menu below')\n",
    "    print(f'1. Perform Sentiment Analysis on the CORD-19 Dataset')\n",
    "    print(f'2. Exit')\n",
    "    choice = int(input(f'Enter your choice: '))\n",
    "    if choice == 1:\n",
    "        print(f'Performing Sentiment Analysis on the CORD-19 Dataset')\n",
    "        print(f'Please wait while the program loads the dataset')\n",
    "    if choice == 2:\n",
    "        print(f'Exiting the program')\n",
    "        exit()\n",
    "    else:\n",
    "        print(f'Invalid choice. Please try again')\n",
    "        main()\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    This function performs the following operations:\n",
    "    1. Removes the punctuations\n",
    "    2. Removes the stopwords\n",
    "    3. Performs stemming\n",
    "    4. Performs lemmatization\n",
    "\n",
    "    :param text:\n",
    "    :return:\n",
    "\n",
    "    Example:\n",
    "    Input: \"This is a sample text!!!\"\n",
    "\n",
    "    Output: \"sample text\"\n",
    "    \"\"\"\n",
    "    # Remove the punctuations\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    # Convert the text to lowercase\n",
    "    text = text.lower()\n",
    "    # Create tokens from the text\n",
    "    tokens = word_tokenize(text)\n",
    "    # Remove the stopwords\n",
    "    tokens = [token for token in tokens if token not in stopwords.words('english')]\n",
    "    # Perform stemming\n",
    "    stemmer = PorterStemmer()\n",
    "    tokens = [stemmer.stem(token) for token in tokens]\n",
    "    # Perform lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    # Join the tokens to form the text\n",
    "    text = ' '.join(tokens)\n",
    "    return text\n",
    "\n",
    "\n",
    "# Function to plot the confusion matrix\n",
    "def plot_confusion_matrix(y_test, y_pred):\n",
    "    \"\"\"\n",
    "    Function to plot the confusion matrix\n",
    "\n",
    "\n",
    "    :param y_test:\n",
    "    :param y_pred:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='g')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted Labels')\n",
    "    plt.ylabel('Actual Labels')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# KNN\n",
    "# Function to train the KNN model\n",
    "def train_knn(X_train, y_train, k):\n",
    "    \"\"\"\n",
    "    Function to train the KNN model\n",
    "\n",
    "    :param X_train:\n",
    "    :param y_train:\n",
    "    :param k:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    return knn\n",
    "\n",
    "\n",
    "# Function to test the KNN model\n",
    "def test_knn(knn, X_test):\n",
    "    \"\"\"\n",
    "    Function to test the KNN model\n",
    "\n",
    "    :param knn:\n",
    "    :param X_test:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    y_pred = knn.predict(X_test)\n",
    "    return y_pred\n",
    "\n",
    "\n",
    "# Function to perform KNN classification\n",
    "def knn_classification(X_train, y_train, X_test, y_test, k):\n",
    "    \"\"\"\n",
    "    Function to perform KNN classification\n",
    "\n",
    "    :param X_train:\n",
    "\n",
    "    :param y_train:\n",
    "    :param X_test:\n",
    "    :param y_test:\n",
    "    :param k:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    knn = train_knn(X_train, y_train, k)\n",
    "    y_pred = test_knn(knn, X_test)\n",
    "    print('Accuracy Score: ', accuracy_score(y_test, y_pred))\n",
    "    print('Confusion Matrix: \\n', confusion_matrix(y_test, y_pred))\n",
    "    print('Classification Report: \\n', classification_report(y_test, y_pred))\n",
    "    plot_confusion_matrix(y_test, y_pred)\n",
    "\n",
    "\n",
    "# Naive Bayes\n",
    "# Function to train the Naive Bayes model\n",
    "def train_naive_bayes(X_train, y_train):\n",
    "    \"\"\"\n",
    "    Function to train the Naive Bayes model\n",
    "  :param X_train:\n",
    "    :param y_train:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    nb = MultinomialNB()\n",
    "    nb.fit(X_train, y_train)\n",
    "    return nb\n",
    "\n",
    "\n",
    "# Function to test the Naive Bayes model\n",
    "def test_naive_bayes(nb, X_test):\n",
    "    \"\"\"\n",
    "    Function to test the Naive Bayes model\n",
    "\n",
    "    :param nb:\n",
    "    :param X_test:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    y_pred = nb.predict(X_test)\n",
    "    return y_pred\n",
    "\n",
    "\n",
    "# Create Class Attribute For Target Variable\n",
    "def create_class_attribute(df):\n",
    "    \"\"\"\n",
    "    Create Class Attribute For Target Variable\n",
    "\n",
    "\n",
    "    :param df:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    df['class'] = df['Sentiment'].apply(lambda x: 1 if x == 'covid-19' else 0)\n",
    "    return df\n",
    "\n",
    "\n",
    "# Create Sentiment Description Attribute For Target Variable\n",
    "def create_sentiment_description_attribute(df):\n",
    "    \"\"\"\n",
    "    Create Sentiment Description Attribute For Target Variable\n",
    "\n",
    "    :param df:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    df['Sentiment_Description'] = df['Sentiment'].apply(lambda x: 'Positive' if x == 'covid-19' else 'Negative')\n",
    "    return df\n",
    "\n",
    "\n",
    "# CREATE DOMAIN ATTRIBUTE FOR TARGET VARIABLE\n",
    "def create_domain_attribute(df):\n",
    "    \"\"\"\n",
    "    CREATE DOMAIN ATTRIBUTE FOR TARGET VARIABLE\n",
    "\n",
    "    :param df:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    df['Domain'] = df['Sentiment'].apply(lambda x: 'COVID-19' if x == 'covid-19' else 'Other')\n",
    "    return df\n",
    "\n",
    "\n",
    "# Function to Preprocess the data\n",
    "def preprocess_data(df):\n",
    "    # Remove the rows with missing values\n",
    "    df.dropna(inplace=True)\n",
    "    # Remove the duplicates\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    # Remove the rows with the class label as 'other'\n",
    "    df = df[df['Sentiment'] != 'other']\n",
    "    # Clean the text\n",
    "    df['cleaned_text'] = df['Abstract'].apply(clean_text)\n",
    "    return df\n",
    "\n",
    "\n",
    "'''\n",
    "#  You have: Data with a set of feature attributes and class attributes. Data pre-processing methods:\n",
    "# Binary, TF, TFIDF, WordsToKeep Models: KNN, Naïve Bayes, Decision Tree Your experiment design should to: Choose the\n",
    "# class attribute (Sentiment or Sentiment_Description) Choose subsets of feature attributes Choose pre-processing\n",
    "# methods Choose different K for KNN Choose Naïvebayes or NaivebayesMultinomialText Choose different parameters,\n",
    "# such as minNumObj, subtree raising, for the decision tree model, J48 For different combinations of the above choices,\n",
    "# run the model on the given data, compare the results, discuss the factors influencing the performance. Finally,\n",
    "# choose the best model for the problem. If the Weka runs too long for a configuration, try to reduce the dictionary\n",
    "# size by the WordsToKeep option.\n",
    "'''\n",
    "\n",
    "'''# 1. Choose the class attribute (Sentiment or Sentiment_Description) # 2. Choose subsets of feature attributes #\n",
    "3. Choose pre-processing methods # 4. Choose different K for KNN # 5. Choose Naïvebayes or NaivebayesMultinomialText\n",
    "# 6. Choose different parameters, such as minNumObj, subtree raising, for the decision tree model, J48 # 7. For\n",
    "different combinations of the above choices, run the model on the given data, compare the results, discuss the\n",
    "factors influencing the performance. # 8. Finally, choose the best model for the problem. If the Weka runs too long\n",
    "for a configuration, try to reduce the dictionary size by the WordsToKeep option.\n",
    "\n",
    "'''\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print_hi('Kevin Mastascusa')\n",
    "    # Load the data\n",
    "    df = pd.read_csv('metadata.csv')\n",
    "    # Print the structure of the data\n",
    "    print(df.info())\n",
    "    # Print the first 10 rows of the data\n",
    "    print(df.head(10))\n",
    "    # Print a summary of the data\n",
    "    print(df.describe(include='all'))\n",
    "    # Print the number of missing values in each column\n",
    "    print(df.isnull().sum())\n",
    "    # Print the number of unique values in each column\n",
    "    print(df.nunique())\n",
    "\n",
    "    print(' ------------------------------------ ')\n",
    "    print(' ------------------------------------ ')\n",
    "\n",
    "'''\n",
    "    # Drop the columns that are not required\n",
    "\n",
    "    # df.drop(['cord_uid', 'sha', 'source_x', 'doi', 'pmcid', 'pubmed_id', 'license', 'abstract', 'publish_time',\n",
    "    #            'authors', 'journal', 'mag_id', 'who_covidence_id', 'arxiv_id', 'pdf_json_files', 'pmc_json_files',\n",
    "    #            'url', 's2_id'], axis=1, inplace=True)\n",
    "    # Print the first 10 rows of the data\n",
    "    # print(df.head(10))\n",
    "    # Print the number of missing values in each column\n",
    "    # print(df.isnull().sum())\n",
    "    # Print the number of unique values in each column\n",
    "    # print(df.nunique())\n",
    "\n",
    "    # Print the number of missing values in each column\n",
    "    # print(df.isnull().sum1())\n",
    "\n",
    "'''\n",
    "\n",
    "\"\"\"Note: for the assignment done by a group, the group submits a single report by anyone of the group members. If\n",
    "multiple inconsistent reports are submitted,  the submitter receives the grade based on his/her own submission. The\n",
    "goal of the project is to systematically evaluate different combinations of data pre-processing methods and\n",
    "classification models for sentiment analysis on self-selected data. Your project should start with a design of the\n",
    "experiments. You have: Data with a set of feature attributes and class attributes. Data pre-processing methods:\n",
    "Binary, TF, TFIDF, WordsToKeep Models: KNN, Naïve Bayes, Decision Tree Your experiment design should to: Choose the\n",
    "class attribute (Sentiment or Sentiment_Description) Choose subsets of feature attributes Choose pre-processing\n",
    "methods Choose different K for KNN Choose Naïvebayes or NaivebayesMultinomialText Choose different parameters,\n",
    "such as minNumObj, subtree raising, for the decision tree model, J48 For different combinations of the above choices,\n",
    "run the model on the given data, compare the results, discuss the factors influencing the performance. Finally,\n",
    "choose the best model for the problem. If the Weka runs too long for a configuration, try to reduce the dictionary\n",
    "size by the WordsToKeep option.\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "# CORD19 ABSTRACT DATASET CLEANING AND PREPROCESSING\n",
    "# Clean the data\n",
    "# Drop the columns that are not required\n",
    "print('Drop the columns that are not required:')\n",
    "df.drop(['cord_uid', 'sha', 'source_x', 'doi', 'pmcid', 'pubmed_id', 'license', 'abstract', 'publish_time', 'authors',\n",
    "         'journal', 'mag_id', 'who_covidence_id', 'arxiv_id', 'pdf_json_files', 'pmc_json_files', 'url', 's2_id'],\n",
    "        axis=1, inplace=True)\n",
    "# Check the structure of the data\n",
    "print('Check the structure of the data:')\n",
    "print(df.info())\n",
    "# Print the first 10 rows of the data\n",
    "print('Print the first 10 rows of the data:')\n",
    "print(df.head(10))\n",
    "# Print a summary of the data\n",
    "print('Print a summary of the data:')\n",
    "print(df.describe(include='all'))\n",
    "# Print the number of missing values in each column\n",
    "print('Number of missing values in each column:')\n",
    "print(df.isnull().sum())\n",
    "# Print the number of unique values in each column\n",
    "print('Number of unique values in each column:')\n",
    "print(df.nunique())\n",
    "# Drop the rows with missing values\n",
    "print('Drop the rows with missing values:')\n",
    "df.dropna(inplace=True)\n",
    "# Print the number of missing values in each column\n",
    "print('Number of missing values in each column:')\n",
    "print(df.isnull().sum())\n",
    "# Print the number of unique values in each column\n",
    "print('Number of unique values in each column:')\n",
    "print(df.nunique())\n",
    "# # Print the class distribution\n",
    "# print('Class distribution:')\n",
    "# print(df['source'].value_counts())\n",
    "# # Plot the class distribution\n",
    "# print('Class distribution plot:')\n",
    "# sns.countplot(df['source'])\n",
    "# plt.show()\n",
    "\n",
    "print(\"MARKER 1\")\n",
    "print(' ------------------------------------ ')\n",
    "print(' ------------------------------------ ')\n",
    "# Add target column for classification.\n",
    "print('Add target column for classification:')\n",
    "df['target'] = df['title'].apply(lambda x: 1 if 'covid-19' in x.lower() else 0)\n",
    "# add target\n",
    "# Print the first 10 rows of the data\n",
    "print('Print the first 10 rows of the data:')\n",
    "print(df.head(10))\n",
    "# Print the number of missing values in each column\n",
    "print('Number of missing values in each column:')\n",
    "print(df.isnull().sum())\n",
    "# Print the number of unique values in each column\n",
    "print('Number of unique values in each column:')\n",
    "print(df.nunique())\n",
    "# Print the class distribution\n",
    "print('Class distribution:')\n",
    "print(df['target'].value_counts())\n",
    "# Plot the class distribution\n",
    "print('Class distribution plot:')\n",
    "sns.countplot(df['target'])\n",
    "plt.show()\n",
    "print(' ------------------------------------ ')\n",
    "print(' ------------------------------------ ')\n",
    "# # Print the first 5 rows of the data\n",
    "# print(df.head())\n",
    "# # Print the number of missing values in each column\n",
    "# print(df.isnull().sum())\n",
    "# # Print the number of unique values in each column\n",
    "# print(df.nunique())\n",
    "# # Print the class distribution\n",
    "# print(df['target'].value_counts())\n",
    "# # Plot the class distribution\n",
    "# sns.countplot(df['target'])\n",
    "# plt.show()\n",
    "\n",
    "print(\"MARKER 2\")\n",
    "print(' ------------------------------------ ')\n",
    "print(' ------------------------------------ ')\n",
    "\n",
    "print('Data Preprocessing:')\n",
    "print('NUMPY ARRAY CONVERSION:')\n",
    "print('Convert the dataframe to numpy array:')\n",
    "numpy_array = df.to_numpy()\n",
    "print('Print the numpy array:')\n",
    "print(numpy_array)\n",
    "print('Print the shape of the numpy array:')\n",
    "print(numpy_array.shape)\n",
    "print('Print the type of the numpy array:')\n",
    "print(type(numpy_array))\n",
    "\n",
    "print('Print the first row of the numpy array:')\n",
    "print(numpy_array[0])\n",
    "print('Print the second row of the numpy array:')\n",
    "print(numpy_array[1])\n",
    "print('Print the third row of the numpy array:')\n",
    "print(numpy_array[2])\n",
    "print('Print the fourth row of the numpy array:')\n",
    "print(numpy_array[3])\n",
    "print('Print the fifth row of the numpy array:')\n",
    "print(numpy_array[4])\n",
    "\n",
    "print('Print the first column of the numpy array:')\n",
    "print(numpy_array[:, 0])\n",
    "print('Print the second column of the numpy array:')\n",
    "print(numpy_array[:, 1])\n",
    "# print(numpy_array[:, 2])\n",
    "# print('Print the fourth column of the numpy array:')\n",
    "# print(numpy_array[:, 3])\n",
    "# print('Print the fifth column of the numpy array:')\n",
    "# print(numpy_array[:, 4])\n",
    "\n",
    "print('Print the first row and first column of the numpy array:')\n",
    "print(numpy_array[0][0])\n",
    "\n",
    "print('Print the first row and second column of the numpy array:')\n",
    "print(numpy_array[0][1])\n",
    "\n",
    "# print('Print the first row and third column of the numpy array:')\n",
    "# print(numpy_array[0][2])\n",
    "#\n",
    "# print('Print the first row and fourth column of the numpy array:')\n",
    "# print(numpy_array[0][3])\n",
    "#\n",
    "# print('Print the first row and fifth column of the numpy array:')\n",
    "# print(numpy_array[0][4])\n",
    "#\n",
    "# print('Print the first row and sixth column of the numpy array:')\n",
    "# print(numpy_array[0][5])\n",
    "\n",
    "# Export as csv file\n",
    "print('Export as csv file:')\n",
    "df.to_csv('CORD19_abstract.csv', index=False)\n",
    "var = open('CORD19_abstract.csv', 'r', encoding='utf-8').readlines()[:5]\n",
    "print(var)\n",
    "\n",
    "print(' ------------------------------------ ')\n",
    "print(' ------------------------------------ ')\n",
    "import nltk\n",
    "# [nltk_data] Error loading stopwords: <urlopen error [SSL:\n",
    "# [nltk_data]     CERTIFICATE_VERIFY_FAILED] certificate verify failed:\n",
    "# [nltk_data]     unable to get local issuer certificate (_ssl.c:997)>\n",
    "\n",
    "import string\n",
    "\n",
    "# from nltk.corpus import stopwords\n",
    "# from nltk.tokenize import word_tokenize\n",
    "# from nltk.stem import PorterStemmer\n",
    "# from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Download the stopwords\n",
    "print('Download the stopwords:')\n",
    "\n",
    "# nltk.download('stopwords')\n",
    "print('text cleaning:')\n",
    "# Convert to lower case\n",
    "print('Convert to lower case:')\n",
    "df['title'] = df['title'].apply(lambda x: x.lower())\n",
    "# Remove punctuation\n",
    "print('Remove punctuation:')\n",
    "df['title'] = df['title'].apply(lambda x: x.translate(str.maketrans('', '', string.punctuation)))\n",
    "# Remove numbers\n",
    "print('Remove numbers:')\n",
    "df['title'] = df['title'].apply(lambda x: x.translate(str.maketrans('', '', string.digits)))\n",
    "# Remove whitespaces\n",
    "print('Remove whitespaces:')\n",
    "df['title'] = df['title'].apply(lambda x: x.strip())\n",
    "# Remove stopwords\n",
    "# print('Remove stopwords:')\n",
    "# stop_words = set(stopwords.words('english'))\n",
    "# df['title'] = df['title'].apply(lambda x: ' '.join([word for word in x.split() if word not in stop_words]))\n",
    "# Remove short words\n",
    "# print('Remove short words:')\n",
    "# df['title'] = df['title'].apply(lambda x: ' '.join([word for word in x.split() if len(word) > 3]))\n",
    "# Lemmatization\n",
    "# print('Lemmatization:')\n",
    "# lemmatizer = WordNetLemmatizer()\n",
    "# df['title'] = df['title'].apply(lambda x: ' '.join([lemmatizer.lemmatize(word) for word in x.split()]))\n",
    "# Print the first 5 rows of the data\n",
    "print('Print the first 5 rows of the data:')\n",
    "print(df.head())\n",
    "# Print the number of missing values in each column\n",
    "\n",
    "print('Number of missing values in each column:')\n",
    "print(df.isnull().sum())\n",
    "# Print the number of unique values in each column\n",
    "print('Number of unique values in each column:')\n",
    "print(df.nunique())\n",
    "# Print the class distribution\n",
    "print('Class distribution:')\n",
    "print(df['target'].value_counts())\n",
    "# Plot the class distribution\n",
    "print('Class distribution plot:')\n",
    "sns.countplot(df['target'])\n",
    "plt.show()\n",
    "\n",
    "print(' ------------------------------------ ')\n",
    "print(' ------------------------------------ ')\n",
    "#KNN\n",
    "print('KNN:')\n",
    "# Import the libraries\n",
    "print('Import the libraries:')\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Create the features and labels\n",
    "print('Create the features and labels:')\n",
    "X = df['title']\n",
    "y = df['target']\n",
    "# Split the data into training and testing sets\n",
    "print('Split the data into training and testing sets:')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# Initialize the TfidfVectorizer\n",
    "print('Initialize the TfidfVectorizer:')\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_df=0.7)\n",
    "# Fit and transform the training data\n",
    "print('Fit and transform the training data:')\n",
    "tfidf_train = tfidf_vectorizer.fit_transform(X_train)\n",
    "# Transform the test set\n",
    "print('Transform the test set:')\n",
    "tfidf_test = tfidf_vectorizer.transform(X_test)\n",
    "# Initialize the KNN classifier\n",
    "print('Initialize the KNN classifier:')\n",
    "knn = KNeighborsClassifier(n_neighbors=2)\n",
    "# Fit the model\n",
    "print('Fit the model:')\n",
    "knn.fit(tfidf_train, y_train)\n",
    "# Predict on the test set\n",
    "print('Predict on the test set:')\n",
    "y_pred = knn.predict(tfidf_test)\n",
    "# Print the accuracy score\n",
    "print('Print the accuracy score:')\n",
    "print('Accuracy score: {}'.format(accuracy_score(y_test, y_pred)))\n",
    "# Print the confusion matrix\n",
    "print('Print the confusion matrix:')\n",
    "print('Confusion matrix:')\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "# Print the classification report\n",
    "print('Print the classification report:')\n",
    "print('Classification report:')\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(' ------------------------------------ ')\n",
    "print(' ------------------------------------ ')\n",
    "\n",
    "#KNN with different k values\n",
    "print('KNN with different k values:')\n",
    "# Import the libraries\n",
    "print('Import the libraries:')\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Create the features and labels\n",
    "print('Create the features and labels:')\n",
    "X = df['title']\n",
    "y = df['target']\n",
    "# Split the data into training and testing sets\n",
    "print('Split the data into training and testing sets:')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# Initialize the TfidfVectorizer\n",
    "print('Initialize the TfidfVectorizer:')\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_df=0.7)\n",
    "# Fit and transform the training data\n",
    "print('Fit and transform the training data:')\n",
    "tfidf_train = tfidf_vectorizer.fit_transform(X_train)\n",
    "# Transform the test set\n",
    "print('Transform the test set:')\n",
    "tfidf_test = tfidf_vectorizer.transform(X_test)\n",
    "# Initialize the KNN classifier\n",
    "print('Initialize the KNN classifier:')\n",
    "knn = KNeighborsClassifier(n_neighbors=2)\n",
    "# Fit the model\n",
    "print('Fit the model:')\n",
    "knn.fit(tfidf_train, y_train)\n",
    "# Predict on the test set\n",
    "print('Predict on the test set:')\n",
    "y_pred = knn.predict(tfidf_test)\n",
    "# Print the accuracy score\n",
    "print('Print the accuracy score:')\n",
    "print('Accuracy score: {}'.format(accuracy_score(y_test, y_pred)))\n",
    "# Print the confusion matrix\n",
    "print('Print the confusion matrix:')\n",
    "print('Confusion matrix:')\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "# Print the classification report\n",
    "print('Print the classification report:')\n",
    "print('Classification report:')\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(' ------------------------------------ ')\n",
    "print(' ------------------------------------ ')\n",
    "\n",
    "#KNN with different k values (k=5) and (k=10) and (k=15) and (k=20)\n",
    "\n",
    "print('KNN with different k values (k=5) and (k=10) and (k=15) and (k=20):')\n",
    "# Import the libraries\n",
    "print('Import the libraries:')\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Create the features and labels\n",
    "print('Create the features and labels:')\n",
    "X = df['title']\n",
    "y = df['target']\n",
    "# Split the data into training and testing sets\n",
    "print('Split the data into training and testing sets:')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# Initialize the TfidfVectorizer\n",
    "print('Initialize the TfidfVectorizer:')\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_df=0.7)\n",
    "# Fit and transform the training data\n",
    "print('Fit and transform the training data:')\n",
    "tfidf_train = tfidf_vectorizer.fit_transform(X_train)\n",
    "# Transform the test set\n",
    "print('Transform the test set:')\n",
    "tfidf_test = tfidf_vectorizer.transform(X_test)\n",
    "# Initialize the KNN classifier\n",
    "print('Initialize the KNN classifier:')\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "# Fit the model\n",
    "print('Fit the model:')\n",
    "knn.fit(tfidf_train, y_train)\n",
    "# Predict on the test set\n",
    "print('Predict on the test set:')\n",
    "y_pred = knn.predict(tfidf_test)\n",
    "# Print the accuracy score\n",
    "print('Print the accuracy score:')\n",
    "print('Accuracy score: {}'.format(accuracy_score(y_test, y_pred)))\n",
    "# Print the confusion matrix\n",
    "print('Print the confusion matrix:')\n",
    "print('Confusion matrix:')\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "# Print the classification report\n",
    "print('Print the classification report:')\n",
    "print('Classification report:')\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(' ------------------------------------ ')\n",
    "print(' ------------------------------------ ')\n",
    "\n",
    "\n",
    "print('KNN with different k values (k=5) and (k=10) and (k=15) and (k=20):')\n",
    "# Import the libraries\n",
    "print('Import the libraries:')\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Create the features and labels\n",
    "print('Create the features and labels:')\n",
    "X = df['title']\n",
    "y = df['target']\n",
    "# Split the data into training and testing sets\n",
    "print('Split the data into training and testing sets:')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# Initialize the TfidfVectorizer\n",
    "print('Initialize the TfidfVectorizer:')\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_df=0.7)\n",
    "# Fit and transform the training data\n",
    "print('Fit and transform the training data:')\n",
    "tfidf_train = tfidf_vectorizer.fit_transform(X_train)\n",
    "# Transform the test set\n",
    "print('Transform the test set:')\n",
    "tfidf_test = tfidf_vectorizer.transform(X_test)\n",
    "# Initialize the KNN classifier\n",
    "print('Initialize the KNN classifier:')\n",
    "knn = KNeighborsClassifier(n_neighbors=10)\n",
    "# Fit the model\n",
    "print('Fit the model:')\n",
    "knn.fit(tfidf_train, y_train)\n",
    "# Predict on the test set\n",
    "print('Predict on the test set:')\n",
    "y_pred = knn.predict(tfidf_test)\n",
    "# Print the accuracy score\n",
    "print('Print the accuracy score:')\n",
    "print('Accuracy score: {}'.format(accuracy_score(y_test, y_pred)))\n",
    "# Print the confusion matrix\n",
    "print('Print the confusion matrix:')\n",
    "print('Confusion matrix:')\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "# Print the classification report\n",
    "print('Print the classification report:')\n",
    "print('Classification report:')\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(' ------------------------------------ ')\n",
    "print(' ------------------------------------ ')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "READ ME\n",
    "metadata.csv is the dataset that is used for this project.\n",
    "The dataset is taken from the following link:\n",
    "https://www.kaggle.com/allen-institute-for-ai/CORD-19-research-challenge\n",
    "\n",
    "The dataset is a collection of research papers related to COVID-19, SARS-CoV-2, and related coronaviruses.\n",
    "\n",
    "The dataset contains the following columns:\n",
    "cord_uid, sha, source_x, title, doi, pmcid, pubmed_id, license, abstract, publish_time, authors, journal,\n",
    "mag_id, who_covidence_id, arxiv_id, pdf_json_files, pmc_json_files, url, s2_id\n",
    "\n",
    "\n",
    "The dataset is preprocessed in the following way:\n",
    "1. The dataset is read using pandas.\n",
    "2. The dataset is converted to numpy array.\n",
    "3. The dataset is converted to lower case.\n",
    "4. The punctuation is removed.\n",
    "5. The numbers are removed.\n",
    "6. The whitespaces are removed.\n",
    "7. The stopwords are removed.\n",
    "8. The short words are removed.\n",
    "9. The lemmatization is performed.\n",
    "10. The dataset is exported as csv file.\n",
    "11. The first 5 rows of the dataset are printed.\n",
    "12. The number of missing values in each column is printed.\n",
    "13. The number of unique values in each column is printed.\n",
    "14. The class distribution is printed.\n",
    "15. The class distribution plot is printed\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-04T16:36:15.156482Z",
     "start_time": "2023-06-04T16:33:53.342891Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
